raw_users:
    type: JSONLocalDataSet
    filepath: data/01_raw/users.jsonl
    load_args:
        multiline: True

raw_tweets:
    type: kedro.contrib.io.pyspark.SparkDataSet
    filepath: data/01_raw/tweets.csv
    file_format: csv
    save_args: 
        mode: overwrite
    load_args:
        header: True
        # schema: id StringType, user_id StringType, created_at TimestampType, source StringType, isReply BooleanType, isQuote BooleanType, hashtags ArrayType(StringType), hashtagsCount ShortType, mentions ArrayType(StringType), mentionsCount ShortType, urls ArrayType(StringType), urlsCount ShortType, symbols ArrayType(StringType), symbolsCount ShortType, sensitive BooleanType, truncated BooleanType, lang StringType, isRetweet BooleanType, text StringType, retweetedAuthor StringType, mediaCount ShortType, pollsCount ShortType, replyTo StringType, quoteOf StringType, quoteCount ShortType, replyCount ShortType, retweetCount ShortType, favoriteCount ShortType
        # inferSchema: True
        # enforceSchema: False
        multiLine: True

parquet_tweets:
    type: kedro.contrib.io.pyspark.SparkDataSet
    filepath: data/02_intermediate/tweets.parquet
    file_format: 'parquet'

raw_test:
    type: kedro.contrib.io.pyspark.SparkDataSet
    filepath: data/01_raw/test.csv
    file_format: csv
    load_args:
        header: True
        # schema: idx integer, name string, timestamp timestamp, text string, date string
        # schema: idx bigint
        inferSchema: True
        # enforceSchema: False
        multiLine: True
    
parquet_test:
    type: kedro.contrib.io.pyspark.SparkDataSet
    filepath: data/02_intermediate/test.parquet
    file_format: 'parquet'

# raw_tweets:
#     type: CSVLocalDataSet
#     filepath: data/01_raw/tweets.csv


labels:
    type: CSVLocalDataSet
    filepath: data/01_raw/labels.csv
    load_args:
        lines: True

